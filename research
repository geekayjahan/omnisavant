# How AI startups are building real moats in the age of commoditized models

**The most defensible AI startups of 2022–2025 aren't winning with better models—they're winning with deeper workflows, proprietary data loops, and business models that make switching economically irrational.** Despite 90% of AI startups failing within five years and 95% of enterprise GenAI pilots delivering no measurable ROI, a distinct cohort has cracked the code: companies like Cursor ($29.3B valuation, >$1B ARR), Sierra ($10B, ~$100M ARR on outcome-based pricing), and Harvey (~$11B, ~$190M ARR) have built compound moats that compound with every customer interaction. The pattern is clear—defensibility in 2025–2026 lives not in model differentiation but at the intersection of workflow embeddedness, proprietary data capture, and novel pricing that aligns vendor economics with customer outcomes. This report maps the specific strategies, architectures, and companies defining this new playbook.

---

## The death of per-seat pricing is reshaping AI economics

The most significant business model shift in enterprise software is happening right now. Seat-based pricing dropped from **21% to 15%** of B2B companies in just twelve months, while hybrid pricing surged from 27% to 41%. A full 73% of AI companies are still experimenting with pricing, testing an average of 3.2 different approaches in their first 18 months. This isn't indecision—it's the market discovering that AI fundamentally breaks the per-seat model, because good AI reduces headcount.

**Outcome-based pricing** has emerged as the sharpest weapon against incumbents. Sierra AI, founded in 2023 by former Salesforce CEO Bret Taylor and former Google VP Clay Bavor, charges roughly **$1.50 per resolved customer interaction**—not per seat, not per API call. The result: $100M ARR in seven quarters, with an 80% resolution rate across enterprise clients like WeightWatchers, Sonos, and ADP. Decagon (founded 2023, $4.5B valuation) offers both per-conversation and per-resolution models. Crescendo.ai, born from General Catalyst in 2024, hit ~$91M ARR by combining $1.25/resolution pricing with a hybrid model that acquired human BPO firm PartnerHero to guarantee 100% ticket resolution—AI handles 90%, humans handle the rest.

This pricing creates a structural counter-position against incumbents. Intercom's shift from $39/seat/month to $0.99 per AI-resolved conversation produced **40% higher adoption rates** and cut one enterprise customer's support costs by 60%. Incumbents like Zendesk and Salesforce are scrambling to follow, but cannibalization anxiety slows them. As Bain Capital Ventures notes, outcome pricing is more durable than pure consumption pricing because it's value-anchored—when token costs drop with each model release, consumption pricing gets undercut, but paying $1.50 for a resolved customer ticket remains compelling regardless of underlying infrastructure costs.

The fundamental tension: AI company gross margins average **50–60%** versus 80–90% for traditional SaaS. This means AI companies must either achieve dramatic scale or find pricing models that capture enough value to overcome the infrastructure cost burden. The winning formula emerging combines a base platform fee, usage/outcome-based upside, high-touch implementation creating switching costs, and systematic data collection feeding a flywheel.

---

## Workflow orchestration, not model quality, creates the deepest technical moats

Harvey AI's most instructive moment wasn't a product launch—it was a retreat. In 2025, the legal AI company **scrapped its proprietary vertical model** after frontier reasoning models from Google, xAI, and OpenAI began outperforming it on Harvey's own BigLaw Bench evaluation. Harvey pivoted to multi-model orchestration and workflow depth instead. The result? Revenue accelerated to an estimated $195M ARR, up 3.9x year-over-year, with a trajectory toward $11B valuation. The lesson is stark: model-level defensibility is fragile; system-level defensibility persists.

The technical pattern that creates durable moats is what Berkeley AI Research calls **"compound AI systems"**—architectures where multiple models, tools, data sources, and human feedback loops combine into something greater than any individual component. Harvey's current architecture decomposes each legal query into specialized subtasks handled by different models (clause extraction versus risk scoring versus research synthesis), then recombines outputs with citation layers that trace every step of reasoning. This isn't a wrapper around GPT-4—it's an orchestration layer that has become a system of record for legal workflows at firms like Latham & Watkins across 60+ countries.

Glean exemplifies another dimension: the **per-customer knowledge graph**. Its enterprise search platform trains smaller, client-specific language models that process enterprise datasets, learning "data language, terminology, code names" unique to each organization. The longer a company uses Glean, the more its AI understands that company's institutional language—creating switching costs that are invisible but enormous. Filevine, in the legal operating system space, spent a decade building CRM, case management, time tracking, and billing before AI arrived. When it did, Filevine extended its core system rather than bolting AI on—lawyers draft demand letters, summarize depositions, and analyze cases within the same environment they already live in daily.

The most defensible architectural patterns, ranked by durability:

- **Workflow orchestration plus data flywheel** (2–5 years to build, highest switching costs): Filevine, Glean, Harvey
- **Hardware-enabled data capture** (capital-intensive, physical moats): Inspiren's AI sensors in senior living, Doxel's construction site computer vision
- **Unique data capture plus domain training** (medium difficulty, strong compound effects): Turing Labs hiring workers with GoPros to create proprietary video datasets, Fyxer employing executive assistants who outnumber engineers 4:1 to generate email training data no web scraper could provide
- **Multi-model routing and orchestration** (moderate defensibility, growing importance): TrueFoundry's LLM Gateway, Martian's learned routing claiming 40% cost reduction
- **Domain-specific embeddings alone** (easily eroded by improving general models): Voyage AI's finance embeddings, now less differentiated as frontier models improve

---

## Fourteen startups that aren't ChatGPT wrappers

The companies below represent distinct moat archetypes. Each has built something structurally difficult to replicate, not just incrementally better.

**Cursor (Anysphere)** stands as the fastest-growing startup in history by some measures: $0 to $100M ARR in twelve months, $500M six months later, exceeding **$1B annualized by November 2025**—all without a dollar of marketing spend. Founded in 2022 by four MIT alumni, Cursor's moat is multi-layered: a VS Code fork preserving familiar UX while re-architecting for AI-native workflows, a proprietary Cursor-Fast model optimized for latency-sensitive coding, codebase-aware context that deepens with use, and strategic acquisitions (Supermaven, Graphite) building an end-to-end developer workflow. At $29.3B valuation, the question isn't whether Cursor has a moat—it's whether the moat withstands GitHub Copilot's distribution advantage and Google's acquihire of Windsurf.

**Mercor** is perhaps the most unconventional success story. Founded in 2023 by three Thiel Fellows in their early twenties, it pivoted from AI-powered hiring to becoming the marketplace connecting domain experts (scientists, doctors, lawyers) with AI labs for RLHF training data. Revenue exploded from $75M ARR in February 2025 to over **$450M ARR by September**—approaching $500M faster than Cursor. The moat: two-sided network effects with 300,000+ experts, performance data that improves matching over time, and a critical market shift when Meta's acquisition of 49% of Scale AI sent OpenAI and Google searching for alternatives. Mercor generated $6M profit in H1 2025, rare for hyper-growth AI.

**Hebbia** ($700M valuation, $130M Series B from a16z) represents the "service-as-a-software" archetype. Founded by George Sivulka, who graduated Stanford in math in 2.5 years and worked at NASA as a teenager, Hebbia's Matrix product processes unlimited documents in a spreadsheet-like interface with full citation transparency. It drives over **2% of OpenAI's daily API volume**. The moat is cross-vertical applicability—unlike Harvey (legal only) or EvenUp (personal injury), Hebbia serves finance, law, government, and pharma, with each vertical's processing patterns improving extraction for the others.

**Dust** ($21.5M raised, ~$100M+ valuation) is the capital-efficiency outlier. Co-founded by Stanislas Polu, who spent three years at OpenAI researching mathematical reasoning in LLMs, and Gabriel Hubert, whose previous startup was acquired by Stripe. Dust's multi-agent architecture lets enterprise teams build narrow, purpose-built AI agents (@supportExpert, @SQLbuddy) connected to internal data sources. With 70%+ weekly adoption rates at companies with 3,000+ employees and $110K+ ARR per employee across just 66 people, Dust proves that deep technical founders building model-agnostic workflow tools can generate outsized efficiency.

**Browserbase** ($300M valuation, $67.5M raised in fifteen months) is building the "Twilio for headless browsers"—cloud infrastructure that AI agents use to navigate websites. Founded by Paul Klein IV, who previously co-founded Stream Club (acquired by Mux), Browserbase has processed 50M+ browser sessions with 20,000+ developer signups. Its investor roster—Jeff Lawson (Twilio founder), Patrick Collison (Stripe), Guillermo Rauch (Vercel)—signals the thesis: every AI agent company that needs web interaction becomes a potential customer. This is infrastructure primitive positioning, the deepest long-term moat category.

Among seed-stage companies worth watching: **Gumloop** ($3.4M raised, Y Combinator W24) landed Instacart, Webflow, and Rippling as customers with just three people and an intern—a no-code AI automation platform that deliberately pivoted from autonomous agents to deterministic workflow automation, understanding that reliability beats autonomy for production use. **Induced AI** ($2.3M seed from Sam Altman and Eric Schmidt) redesigned Chromium itself for native AI agent use, including built-in memory, file system, and auto-2FA—"RPA 3.0" with an architectural moat in the browser redesign itself.

---

## The human-in-the-loop isn't a limitation—it's the deepest switching cost

In regulated industries, the requirement for human oversight has become perhaps the most underappreciated moat in AI. When clinicians at Johns Hopkins (6,700 physicians) or Mayo Clinic (2,000+) are trained on Abridge's AI clinical documentation workflow—developing muscle memory around its specific interface, calibrating trust in its outputs, learning when to override—the switching cost transcends software. It becomes a **human retraining cost** multiplied across thousands of professionals.

Abridge ($250M Series D, 2025) exemplifies the pattern. Led by a cardiologist CEO and CMU ML professor CTO, it processes hundreds of thousands of clinical encounters weekly across 100+ health systems. Every time a doctor edits an AI-generated note, that correction feeds back into the model—a human-in-the-loop system that doubles as a training data flywheel. The "Linked Evidence" feature traces every AI output to source information, creating audit trails that become compliance dependencies. Abridge has expanded from clinical documentation into revenue cycle intelligence and prior authorization, using its clinical workflow foothold as a wedge into the entire healthcare operations stack.

In financial services, the compliance moat is equally powerful. Financial institutions spend **~$30 billion annually** on human compliance analysts. Greenlite, an AI agent platform for AML investigations and sanction reviews, has spent years building domain-specific data and iterative accuracy that, as QED Investors noted, "rivals could write a toy KYC demo in days, but Greenlite's production system took years of data and iteration." The Federal Reserve's model risk management framework explicitly requires human oversight, and the EU AI Act's Article 19 mandates that high-risk AI providers retain auto-generated logs for 6+ months—creating audit infrastructure dependencies that become structural moats.

The AI Governance market is projected to grow at **49.2% CAGR through 2034**, signaling that enterprises are prioritizing auditability over deployment speed. The strategic implication: compliance-native architecture—built with data provenance, explainability wrappers, human oversight circuit-breakers, and immutable audit trails from day one—creates barriers that compound over time. Each month of compliance history makes switching more painful, because regulatory continuity demands consistent audit trail formats.

---

## $202 billion in AI funding reveals a bifurcating market

The AI startup ecosystem has split into two worlds. A tiny elite attracts unprecedented capital at historic valuations, while the vast middle faces existential margin pressure, feature absorption, and runway cliffs.

Global AI venture funding hit **$202.3B in 2025**, capturing roughly half of all global VC investment—up 75% from 2024. But concentration is extreme: **58% went to megarounds of $500M+**, with fifteen companies securing rounds above $2B and collectively absorbing over $100B. Foundation model companies alone raised $80B (40% of all AI funding). At the application layer, enterprise AI spending tripled to $37B, with startups capturing 63% market share—up from 36%. Yet Nvidia still commands 88% of AI chip sales, with fiscal 2025 revenue hitting $130.5B at 65% operating margins, and hyperscalers spending $380B+ on AI infrastructure.

A new deal structure has emerged that reshapes the exit landscape: the **"License & Acquihire."** Microsoft paid $650M to license Inflection AI's models while hiring co-founder Mustafa Suleyman as CEO of Microsoft AI—leaving Inflection a licensing shell. Google paid $2.7B for Character.AI's IP and returning founders. Amazon absorbed 66% of Adept AI's employees for $25M—reducing the company to approximately four people. These aren't acquisitions in the traditional sense; they're talent extractions that create zombie companies while sidestepping antitrust scrutiny. The FTC is investigating multiple deals, but the pattern is accelerating.

The categories showing consolidation versus fragmentation reveal where moats form. **AI coding has consolidated hard**: GitHub Copilot (42% share, 20M+ users), Claude Code, and Cursor hold 70%+ combined share of a $4B market, with Google's acquihire of Windsurf further compressing the field. **Foundation models are winner-take-few** by capital requirement—training frontier models costs billions. But **AI sales remains startup-dominated** (78% startup share) because workflows sit outside incumbent platforms, and **AI finance/operations** shows 91% startup share as incumbents like Intuit are paralyzed by accuracy demands in regulated domains.

The mortality data is sobering: 966 startups shut down in 2024 (up 25.6% from 2023), with Series B shutdowns up 133%. An estimated **90% of AI startups** fail within five years—significantly worse than the ~70% rate for traditional tech startups. The 42% failure rate attributed to lack of market demand, combined with 42% of companies abandoning most AI initiatives in 2025 (up from 17% in 2024), suggests a massive shakeout is underway.

---

## Six counterintuitive strategies the survivors are using

The startups building durable moats are often doing the opposite of conventional wisdom.

**Strategy 1: The "Data Trojan Horse" wedge.** Rather than building broad platforms, the most successful AI entrants dramatically narrow focus to a single painful problem for a single "hero user"—the sales ops manager manually cleaning lead data, the compliance analyst drowning in alerts. The tool solves that one problem, captures proprietary data in the process, then expands. Clay spent six years building its foundation before finding product-market fit in 2022, then grew from $1M to $100M ARR in two years. Its co-founder said: "The most counterintuitive decision we made was to deliberately shrink our market focus."

**Strategy 2: Charging more, not less.** Harvey commands enterprise premium pricing precisely because it solves specific, high-value legal problems better than general-purpose tools. Microsoft prices Office 365 Copilot at $30/user/month as a deliberate premium signal. Chargeflow charges 25% of recovered chargebacks—pricing that would seem absurd by SaaS standards but aligns perfectly with value delivered.

**Strategy 3: The human layer as counterintuitive advantage.** Arcline uses AI for 80% of legal work and elite lawyers for the critical 20%. Crescendo.ai acquired an entire BPO operation. As Latitude Media observed: "A curated team of experts becomes part of the product DNA. Over time, that can translate to stronger retention and a better user experience." The human layer is harder to scale but also harder to copy.

**Strategy 4: Compliance as offense.** Startups like Greenlite and Parcha enter enterprises through the unglamorous compliance door—overworked teams facing regulatory pressure and no budget for innovation. Once embedded in compliance workflows, expansion follows. QED Investors frames this sharply: "The winners won't just make compliance more efficient. They'll redefine what counts as 'doing the work.'"

**Strategy 5: Anti-hype positioning.** As Sam Altman himself admitted AI is "likely a bubble," companies emphasizing accuracy, transparency, and domain depth over AI spectacle are winning enterprise trust. Abridge's "Linked Evidence" feature, which traces every output to source material, sells better than any chatbot demo. Some companies now market "100% LLM-Free" products. The anti-hype correction creates space for contrarian positioning.

**Strategy 6: Decision traces as the new data moat.** Foundation Capital's Ashu Garg identified perhaps the most novel moat: when AI agents execute workflows, they create structured decision traces—"a living record of how context turned into action." These persist what inputs were gathered, what policies applied, what exceptions were granted, and why. Enterprises almost never have this data, and once they do, it compounds into an irreplaceable operational asset.

---

## A framework for evaluating AI startup defensibility

Based on synthesized research from leading VCs and the patterns above, AI startup defensibility can be evaluated across three tiers that build on each other.

**Tier 1 (Foundation)** covers execution speed, domain expertise, and AI engineering sophistication beyond API wrappers. These are necessary but insufficient—they get you into the game but don't keep you there.

**Tier 2 (Emerging Moats)** evaluates workflow integration depth (is the product embedded in daily work or occasional use?), human-in-the-loop design (does usage create calibration investment?), compliance-native architecture (built-in or bolted-on?), and counter-positioning through pricing that exploits incumbent weaknesses.

**Tier 3 (Compounding Moats)** assesses what actually creates durability: proprietary data loops where usage generates non-replicable training data; process power where years of edge-case engineering create the gap between demo and production (the "99% Rule"—reaching 99% reliability takes 10–100x the effort of an MVP); cornered resources like government contracts requiring security clearances; network effects where each customer makes the product better for all; and combined human-plus-technical switching costs where replacement requires retraining people and migrating data simultaneously.

The companies scoring highest across all three tiers share a common architecture: they sit in the **execution path** of critical workflows, capture **proprietary decision data** as a byproduct of delivering value, price on **outcomes** that align incentives, and embed **human oversight** that creates both regulatory compliance and switching costs. Sierra (outcome pricing + forward-deployed engineering + deep integrations + usage data), Cursor (developer workflow embedding + proprietary model + codebase context + community ecosystem), and Harvey (multi-model orchestration + legal workflow depth + compliance trust + decision traces) each execute all four elements simultaneously.

The fundamental insight across all research: **the companies that will endure aren't competing against OpenAI—they're building on top of it, embedding into the workflows, data, and trust layers that foundation model providers can't reach.** As Insight Partners put it: the next generation of AI companies won't win by having better models. They'll win by being the place where work is created, shared, stored, and improved—one automated workflow at a time.

## Conclusion

Three non-obvious takeaways emerge from this research. First, **Harvey's decision to scrap its proprietary model** is the single most important signal in the AI startup landscape—it proves that even well-funded vertical AI companies can't maintain model-level differentiation against frontier labs, pushing all defensibility to the system and workflow layer. Second, the **"License & Acquihire" deal structure** has fundamentally altered the exit calculus—for many AI startups, the realistic outcome is talent absorption by Big Tech, not IPO, which means founders should either build moats deep enough to remain independent or accept acquihire as the likely endgame. Third, **the 95% failure rate of enterprise GenAI pilots** creates a paradoxical opportunity: companies that can guarantee outcomes (via human-in-the-loop hybrid models and outcome-based pricing) command premium positioning precisely because most AI deployments disappoint. The survivors of this shakeout won't be the companies with the best AI—they'll be the companies whose AI is most painfully difficult to remove.